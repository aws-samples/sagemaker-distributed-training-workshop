{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad542e7-9ef8-41d1-9d6c-3c6c2efb7f19",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Fine-tune DeepSeek-R1-Distill-Qwen-7B using SageMaker Hyperpod recipes and ModelTrainer\n",
    "\n",
    "In this notebook, we fine-tune [deepseek-ai/DeepSeek-R1-Distill-Qwen-7B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B) on Amazon SageMaker AI, using SageMaker Hyperpod recies and [ModelTrainer](https://sagemaker.readthedocs.io/en/v2.239.0/api/training/model_trainer.html) class\n",
    "\n",
    "Recipe: [DeepSeek R1 Distill Qwen 7b - LoRA](https://github.com/aws/sagemaker-hyperpod-recipes/blob/main/recipes_collection/recipes/fine-tuning/deepseek/hf_deepseek_r1_distilled_qwen_7b_seq16k_gpu_lora.yaml)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca016c-d4fa-4213-a7b3-03b449551449",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Our first step is to install Libraries we need on the client to correctly prepare our dataset and start our training/evaluations jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa8eb4a-ab28-4f8a-8a5a-ba42c1752382",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade \"setuptools\" \"sagemaker==2.239.1\" \"graphene\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b01f58-df1e-4f86-8647-98539bac3cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.modules import Session\n",
    "from sagemaker.modules.train import ModelTrainer\n",
    "from sagemaker.modules.configs import Compute\n",
    "from sagemaker.modules.configs import Networking\n",
    "from sagemaker.modules.configs import FileSystemDataSource\n",
    "from sagemaker.modules.configs import S3DataSource\n",
    "from sagemaker.modules.configs import InputData\n",
    "from sagemaker.modules.configs import StoppingCondition\n",
    "from sagemaker.modules.configs import SourceCode\n",
    "from typing import Any\n",
    "from utility import *\n",
    "import sagemaker\n",
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f308a1a-4ebc-4bf6-bc83-dcd30aa9013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "\n",
    "# HuggingFace Model ID\n",
    "model_id = \"deepseek-ai/DeepSeek-R1\"\n",
    "\n",
    "# VPC config\n",
    "network_config={\n",
    "   \"subnets\": [\"subnet-xxxx\"], # e.g. ['subnet-xxxx','subnet-yyyyy']\n",
    "   \"security_group_ids\": [\"sg-xxxx\"] # e.g. [\"sg-xxxx\"]\n",
    "}\n",
    "\n",
    "# FSx mount name\n",
    "fsx_mount_point='/xxxx'\n",
    "\n",
    "# HuggingFace token\n",
    "hf_token=\"<>\"\n",
    "\n",
    "fsx_dir_basemodel=\"deepseek_r1_671b_tj\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c41cbba-33e7-40b5-a740-0409f6ee9b3e",
   "metadata": {},
   "source": [
    "# Common functions \n",
    "\n",
    "Let us define some utility function to run model training using the SageMaker ModelTrainer class.\n",
    "\n",
    "For additional information about ModelTrainer, you can refer to Accelerate your ML lifecycle using the new and improved Amazon SageMaker Python SDK â€“ Part 1: ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1071fc0-0ddb-45e6-8d86-25aaa95de764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_trainer(\n",
    "    use_recipes: bool,\n",
    "    compute: dict,\n",
    "    network: dict,\n",
    "    data_channel: dict,\n",
    "    action: str,\n",
    "    hyperparameters: dict ={},\n",
    "    source_code: str=None,\n",
    "    training_recipe: str=None,\n",
    "    recipe_overrides: str=None,\n",
    "    image_uri: str=None\n",
    ") -> ModelTrainer:\n",
    "    \"\"\"\n",
    "    Creates and executes a model training job using SageMaker.\n",
    "    \n",
    "    Args:\n",
    "        use_recipes (bool): Flag to determine if using SageMaker recipes\n",
    "        compute (dict): Compute configuration for training\n",
    "        source_code (str): Path to source code\n",
    "        network (dict): Network configuration\n",
    "        data_channel (dict): Data channel configuration\n",
    "        action (str): Action identifier for job naming\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If required parameters are missing or invalid\n",
    "    \"\"\"\n",
    "    # Parameter validation\n",
    "    required_params = {\n",
    "        'use_recipes': use_recipes,\n",
    "        'compute': compute,\n",
    "        **({'source_code': source_code} if source_code is not None else {}),\n",
    "        'network': network,\n",
    "        'data_channel': data_channel,\n",
    "        'action': action,\n",
    "        **({'training_recipe': training_recipe} if training_recipe is not None else {}),\n",
    "        **({'recipe_overrides': recipe_overrides} if recipe_overrides is not None else {}),\n",
    "    }\n",
    "    \n",
    "    for param_name, param_value in required_params.items():\n",
    "        if param_value is None:\n",
    "            raise ValueError(f\"Required parameter '{param_name}' is missing\")\n",
    "            \n",
    "\n",
    "    # Job name creation\n",
    "    job_name = f'model-trainer-deepseek-{action}'\n",
    "\n",
    "    # Image URI selection\n",
    "    if image_uri is None or len(image_uri) == 0:\n",
    "        if use_recipes:\n",
    "            image_uri = (\n",
    "                \"658645717510.dkr.ecr.us-east-1.amazonaws.com/smdistributed-modelparallel:2.4.1-gpu-py311-cu121\"\n",
    "            )\n",
    "        else:\n",
    "            image_uri = sagemaker.image_uris.retrieve(\n",
    "                framework=\"pytorch\",\n",
    "                region=sagemaker_session.boto_session.region_name,\n",
    "                version=\"2.4\",\n",
    "                instance_type=compute.instance_type,\n",
    "                image_scope=\"training\"\n",
    "            )\n",
    "\n",
    "    # Setting up stopping condition\n",
    "    stopping_condition = StoppingCondition(max_runtime_in_seconds=43200)\n",
    "\n",
    "    # Estimator configuration\n",
    "    estimator_config = {\n",
    "        'training_image': image_uri,\n",
    "        'source_code': source_code,\n",
    "        'networking': network,\n",
    "        'compute': compute,\n",
    "        'base_job_name': job_name,\n",
    "        'stopping_condition': stopping_condition\n",
    "    }\n",
    "\n",
    "    if(len(hyperparameters) != 0):\n",
    "        estimator_config.update({'hyperparameters':hyperparameters})\n",
    "\n",
    "    if(source_code is None):\n",
    "        estimator_config.pop('source_code')\n",
    "\n",
    "    # Create and execute model trainer\n",
    "    try:\n",
    "        if(use_recipes):\n",
    "            estimator_config.update({'training_recipe':training_recipe})\n",
    "            estimator_config.update({'recipe_overrides':recipe_overrides})\n",
    "            estimator_config.update({'requirements':\"scripts/requirements.txt\"})\n",
    "    \n",
    "            print(f'estimator_config:{estimator_config}')\n",
    "            model_trainer= ModelTrainer.from_recipe(**estimator_config) \n",
    "        else: \n",
    "            print(f'estimator_config:{estimator_config}')\n",
    "            model_trainer= ModelTrainer(**estimator_config)\n",
    "        \n",
    "        return model_trainer\n",
    "        #model_trainer.fit(input_data_config=[data_channel], wait=True)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to create or execute model trainer: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb881beb-0913-412e-9c82-9f1594e0f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute = ComputeCreator.create(\n",
    "        instance_type=\"ml.c5.18xlarge\",\n",
    "        instance_count=1,\n",
    "    )\n",
    "\n",
    "verify_path=fsx_mount_point + \"/\" + fsx_dir_basemodel\n",
    "\n",
    "data_channel = FSxDataChannelCreator.create_channel(\n",
    "        directory_path=verify_path\n",
    "    )\n",
    "\n",
    "network=NetworkConfigCreator.create_network_config(network_config)\n",
    "\n",
    "source_code = SourceCode(source_dir=\"scripts\", entry_script=\"verify.sh\")\n",
    "\n",
    "print(f'Compute Instance created:{compute} of type {type(compute)}\\n\\n')\n",
    "print(f'Data Channel created:{data_channel} of type {type(data_channel)}\\n\\n')\n",
    "print(f'network created:{network} of type {type(network)}]n\\n')\n",
    "print(f'source_code created:{source_code} of type {type(source_code)}')\n",
    "\n",
    "model_trainer=create_model_trainer(use_recipes=False,\n",
    "    compute=compute,\n",
    "    network=network,\n",
    "    data_channel=data_channel,\n",
    "    action=\"verify\",\n",
    "    source_code=source_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3af127-89a4-4632-ae1b-970fe37287c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.train(input_data_config=[data_channel], wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018e0c8e-cdd0-4dd3-9106-2b8fe80482af",
   "metadata": {},
   "source": [
    "# STEP 1: Download model to Amazon FSx for Lustre directory "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adce88a0-35a4-4b7a-a9e2-8572e0759a31",
   "metadata": {},
   "source": [
    "In this step, we will download the DeepSeek-R1 model to FSx directory.\n",
    "\n",
    "Select the instance type, FSx data channel, network configuration for the training job, source code and define the ModelTrainer class to run the training job on ml.c5.18xlarge instance to download DeepSeek-R1 model from huggingface hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa29e6b-4817-4942-b4c0-60e44fa1c0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create compute instance\n",
    "compute = ComputeCreator.create(\n",
    "    instance_type=\"ml.c5.18xlarge\",\n",
    "    instance_count=1\n",
    ")\n",
    "\n",
    "# Create FSx data channel\n",
    "data_channel = FSxDataChannelCreator.create_channel(\n",
    "    directory_path=fsx_mount_point\n",
    ")\n",
    "\n",
    "# Create network configuration\n",
    "network = NetworkConfigCreator.create_network_config(network_config)\n",
    "\n",
    "# Set up source code configuration\n",
    "source_code = SourceCode(\n",
    "    source_dir=\"scripts\",\n",
    "    entry_script=\"download.py\"\n",
    ")\n",
    "\n",
    "# Print configuration details\n",
    "print(f'Compute Instance created: {compute}')\n",
    "print(f'Type: {type(compute)}\\n')\n",
    "\n",
    "print(f'Data Channel created: {data_channel}')\n",
    "print(f'Type: {type(data_channel)}\\n')\n",
    "\n",
    "print(f'Network created: {network}')\n",
    "print(f'Type: {type(network)}\\n')\n",
    "\n",
    "print(f'Source code created: {source_code}')\n",
    "print(f'Type: {type(source_code)}\\n')\n",
    "\n",
    "# Define hyperparameters\n",
    "hyperparameters = {\n",
    "    \"model_id\": model_id,      # Hugging Face model id\n",
    "    \"hf_token\": hf_token,\n",
    "    \"local_fsx_dir\": fsx_dir_basemodel\n",
    "}\n",
    "\n",
    "# Create model trainer\n",
    "model_trainer = create_model_trainer(\n",
    "    use_recipes=False,\n",
    "    compute=compute,\n",
    "    network=network,\n",
    "    data_channel=data_channel,          \n",
    "    action=\"download\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    source_code=source_code\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bd5b42-8034-4e4f-9792-56a9ae08790e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_trainer.train(input_data_config=[data_channel], wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0620499-2abe-4876-a7b1-73e48c89be59",
   "metadata": {},
   "source": [
    "# STEP 2: Convert DeepSeek R1 from FP8 to BF16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789fc686-30fa-47d1-9083-0751e24be1ef",
   "metadata": {},
   "source": [
    "HyperPod recipes disable FP8 in the QLoRA and LoRA recipes. BF16 is the most optimal precision type for generalizing PEFT training configurations to various datasets. That being said, the default weights provided by the DeepSeek team on their official R1 repository are of type FP8. To ensure stable fine-tuning for a DeepSeek-R1 model, we will first convert it to BF16 using the fp8_cast_bf16.py command-line script provided by DeepSeek. Executing this script, will copy over the converted BF16 weights in safetensor format to the specified output directory.\n",
    "\n",
    "We will use ModelTrainer class to execute the conversion using training jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0a5425-e252-483a-bae5-5346aca5662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "FSX_MODELDIR_BF16 = \"deepseek-r1-bf16\"\n",
    "FSX_DIR_PATH = f\"{fsx_mount_point}/{fsx_dir_basemodel}\"\n",
    "\n",
    "# Create compute instance\n",
    "compute = ComputeCreator.create(\n",
    "    instance_type=\"ml.c5.18xlarge\",\n",
    "    instance_count=1\n",
    ")\n",
    "\n",
    "# Create FSx data channel\n",
    "data_channel = FSxDataChannelCreator.create_channel(\n",
    "    directory_path=FSX_DIR_PATH\n",
    ")\n",
    "\n",
    "# Create network configuration\n",
    "network = NetworkConfigCreator.create_network_config(network_config)\n",
    "\n",
    "# Set up source code configuration\n",
    "source_code = SourceCode(\n",
    "    source_dir=\"scripts\",\n",
    "    entry_script=\"convert.sh\"\n",
    ")\n",
    "\n",
    "# Print configuration details\n",
    "print(f'Compute Instance created: {compute}')\n",
    "print(f'Type: {type(compute)}\\n')\n",
    "\n",
    "print(f'Data Channel created: {data_channel}')\n",
    "print(f'Type: {type(data_channel)}\\n')\n",
    "\n",
    "print(f'Network created: {network}')\n",
    "print(f'Type: {type(network)}\\n')\n",
    "\n",
    "print(f'Source code created: {source_code}')\n",
    "print(f'Type: {type(source_code)}\\n')\n",
    "\n",
    "# Define hyperparameters for model conversion\n",
    "hyperparameters = {\n",
    "    \"model_id\": model_id,          # Hugging Face model id\n",
    "    \"hf_token\": hf_token,\n",
    "    \"converted_fsx_dir\": FSX_MODELDIR_BF16\n",
    "}\n",
    "\n",
    "# Create model trainer for conversion\n",
    "model_trainer = create_model_trainer(\n",
    "    use_recipes=False,\n",
    "    compute=compute,\n",
    "    network=network,\n",
    "    data_channel=data_channel,          \n",
    "    action=\"convert\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    source_code=source_code\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d433e769-171d-491a-8e39-5fe3a2b5ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.train(input_data_config=[data_channel], wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e39be14-676a-4121-ab0b-2e6a7adbac26",
   "metadata": {},
   "source": [
    "# STEP 3: Fine-tune the DeepSeek-R1 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a289079d-b40f-4eac-b4d1-333e4007ec3f",
   "metadata": {},
   "source": [
    "Our next phase involves the fine-tuning of the DeepSeek-R1 model utilizing two ml.p5.48xlarge instances, leveraging distributed training. We'll implement this through SageMaker's recipe \"hf_deepseek_r1_671b_seq8k_gpu_qlora\", which incorporates the Quantized Low-Rank Adaptation (QLoRA) methodology. QLoRA makes LLM trainable on limited compute by quantizing the base model to 4-bit precision while using small, trainable low-rank adapters for fine-tuning, dramatically reducing memory requirements without sacrificing model quality.\n",
    "\n",
    "We can override recipe parameters, to tune the script to our needs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fd9e36-b3fb-4ee3-b448-bef135b01931",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_overrides = {\n",
    "    \"run\": {\n",
    "        \"results_dir\": \"/opt/ml/model\",\n",
    "    },\n",
    "    \"exp_manager\": {\n",
    "        \"exp_dir\": \"/opt/ml/input/data/modelweights/output/\",\n",
    "        \"explicit_log_dir\": \"/opt/ml/output/tensorboard\",\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"hf_model_name_or_path\": \"/opt/ml/input/data/modelweights/\",\n",
    "        \"data\": {\n",
    "            \"use_synthetic_data\": True,\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d4903b-8565-4859-acd6-3aae1ce3c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create compute configuration with P5 instances\n",
    "compute = ComputeCreator.create(\n",
    "    instance_type=\"ml.p5.48xlarge\",\n",
    "    instance_count=2\n",
    ")\n",
    "\n",
    "# Construct FSx directory path for model\n",
    "fsx_dir_path = f\"{fsx_mount_point}/{fsx_dir_basemodel}/{fsx_modeldir_bf16}\"\n",
    "\n",
    "# Create FSx data channel\n",
    "data_channel = FSxDataChannelCreator.create_channel(\n",
    "    directory_path=fsx_dir_path\n",
    ")\n",
    "\n",
    "# Set up network configuration\n",
    "network = NetworkConfigCreator.create_network_config(network_config)\n",
    "\n",
    "# Print configuration details\n",
    "print(f'Compute Instance created: {compute}')\n",
    "print(f'Type: {type(compute)}\\n')\n",
    "\n",
    "print(f'Data Channel created: {data_channel}')\n",
    "print(f'Type: {type(data_channel)}\\n')\n",
    "\n",
    "print(f'Network created: {network}')\n",
    "print(f'Type: {type(network)}\\n')\n",
    "\n",
    "# Create model trainer for fine-tuning\n",
    "model_trainer = create_model_trainer(\n",
    "    use_recipes=True,\n",
    "    compute=compute,\n",
    "    network=network,\n",
    "    data_channel=data_channel,          \n",
    "    action=\"finetune\",\n",
    "    training_recipe='fine-tuning/deepseek/hf_deepseek_r1_671b_seq8k_gpu_qlora',\n",
    "    recipe_overrides=recipe_overrides                       \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c0595-c3c9-4609-b5d2-0cf595b9b0c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_trainer.train(input_data_config=[data_channel], wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa21bd0-6c98-404d-8bcd-2eb1e9104f9c",
   "metadata": {},
   "source": [
    "# STEP 4: Merge the trained adapter with the base model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd4cb4c-96bb-4351-bb82-7bb04b1df291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and Configuration\n",
    "ECR_IMAGE_URI = \"658645717510.dkr.ecr.us-east-1.amazonaws.com/smdistributed-modelparallel:2.4.1-gpu-py311-cu121\"\n",
    "\n",
    "# Create compute configuration with P5 instance\n",
    "compute = ComputeCreator.create(\n",
    "    instance_type=\"ml.p5.48xlarge\",\n",
    "    instance_count=1\n",
    ")\n",
    "\n",
    "# Construct FSx directory path for model weights\n",
    "fsx_dir_path = f\"{fsx_mount_point}/{fsx_dir_basemodel}/{fsx_modeldir_bf16}\"\n",
    "\n",
    "# Create FSx data channel for model access\n",
    "data_channel = FSxDataChannelCreator.create_channel(\n",
    "    directory_path=fsx_dir_path\n",
    ")\n",
    "\n",
    "# Set up network configuration\n",
    "network = NetworkConfigCreator.create_network_config(network_config)\n",
    "\n",
    "# Print configuration details for verification\n",
    "print(f'Compute Instance created: {compute}')\n",
    "print(f'Type: {type(compute)}\\n')\n",
    "\n",
    "print(f'Data Channel created: {data_channel}')\n",
    "print(f'Type: {type(data_channel)}\\n')\n",
    "\n",
    "print(f'Network created: {network}')\n",
    "print(f'Type: {type(network)}\\n')\n",
    "\n",
    "# Define hyperparameters for model parallel training\n",
    "hyperparameters = {\n",
    "    \"mp_parameters\": {\n",
    "        #\"tensor_parallel_degree\": 1\n",
    "    }\n",
    "}\n",
    "\n",
    "# Configure source code location and entry point\n",
    "source_code = SourceCode(\n",
    "    source_dir=\"scripts\",\n",
    "    entry_script=\"cli-inference.sh\"\n",
    ")\n",
    "\n",
    "# Create model trainer for adapter merging\n",
    "model_trainer = create_model_trainer(\n",
    "    use_recipes=False,\n",
    "    compute=compute,\n",
    "    network=network,\n",
    "    data_channel=data_channel,          \n",
    "    action=\"mergeadapter\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    source_code=source_code,\n",
    "    image_uri=ECR_IMAGE_URI\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99be7ebc-a881-4abf-972b-0d78ef1a3bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.train(input_data_config=[data_channel], wait=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
