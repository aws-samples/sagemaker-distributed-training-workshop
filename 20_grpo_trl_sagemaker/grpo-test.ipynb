{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1f2d07c-8415-4c94-8997-63513ae1bc15",
   "metadata": {},
   "source": [
    "# Use GRPO to Fine-Tune Qwen2.5-0.5B-Instruct with TRL\n",
    "\n",
    "This notebook explains how you can use GRPO with the help of Hugging Face [TRL](https://huggingface.co/docs/trl/index) on Amazon SageMaker. \n",
    "\n",
    "**This notebook is validated and optimized to run on `ml.p4d.24xlarge` instances**\n",
    "\n",
    "\n",
    "Hugging Face shares the support of GRPO and PyTorch FSDP (Fully Sharded Data Parallel). FSDP and GRPO allow you now to fine-tune foundation models.\n",
    "\n",
    "* [PyTorch FSDP](https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/) is a data/model parallelism technique that shards model across GPUs, reducing memory requirements and enabling the training of larger models more efficiently​​​​​​.\n",
    "* GRPO is a training method that leverages Rienforcment learning to fine-tune and/or train foundation model\n",
    "\n",
    "This notebook walks you thorugh how to fine-tune open LLMs from Hugging Face using Amazon SageMaker.\n",
    "\n",
    "## 1. Setup Development Environment\n",
    "\n",
    "Our first step is to install Hugging Face Libraries we need on the client to correctly prepare our dataset and start our training/evaluations jobs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7712088-324c-4432-b29b-c978f9b16570",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers \"datasets[s3]==2.18.0\" \"sagemaker>=2.190.0\" --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8742197-92e5-4c11-a783-89e594cf0ed9",
   "metadata": {},
   "source": [
    "Log in huggingface hub to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47b0ca65-2bb6-4202-b6e0-3af039d4c22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"\") # ADD YOUR HF TOKEN HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511ebf51-4d7c-4bde-8f8b-25f8b6d787dd",
   "metadata": {},
   "source": [
    "If you are going to use Sagemaker in a local environment. You need access to an IAM Role with the required permissions for Sagemaker. You can find [here](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) more about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80c7e2ef-2af8-4eda-b4d3-2184ac931a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/28/25 16:36:30] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> PyTorch version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.5</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> available.                                          <a href=\"file:///opt/conda/lib/python3.12/site-packages/datasets/config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/datasets/config.py#58\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">58</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/28/25 16:36:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m PyTorch version \u001b[1;36m2.5\u001b[0m.\u001b[1;36m1\u001b[0m available.                                          \u001b]8;id=149223;file:///opt/conda/lib/python3.12/site-packages/datasets/config.py\u001b\\\u001b[2mconfig.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=925262;file:///opt/conda/lib/python3.12/site-packages/datasets/config.py#58\u001b\\\u001b[2m58\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> TensorFlow version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.18</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> available.                                      <a href=\"file:///opt/conda/lib/python3.12/site-packages/datasets/config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/datasets/config.py#95\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">95</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m TensorFlow version \u001b[1;36m2.18\u001b[0m.\u001b[1;36m0\u001b[0m available.                                      \u001b]8;id=37056;file:///opt/conda/lib/python3.12/site-packages/datasets/config.py\u001b\\\u001b[2mconfig.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=417656;file:///opt/conda/lib/python3.12/site-packages/datasets/config.py#95\u001b\\\u001b[2m95\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sagemaker\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from transformers import AutoTokenizer\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1448f86b-db4f-4c3a-9f17-cf8ac69f463e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::783764584149:role/service-role/AmazonSageMaker-ExecutionRole-20241230T144802\n",
      "sagemaker bucket: sagemaker-us-east-1-783764584149\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket=None\n",
    "\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sagemaker_session = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sagemaker_session.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sagemaker_session.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f898674-71fa-4377-a9c6-3f42fff9ca19",
   "metadata": {},
   "source": [
    "# 2. Create and prepare the dataset\n",
    "\n",
    "In this example, we use the mathematic data to teach the model mathematical reasoning. We are going to use the [Jiayi-Pan/Countdown-Tasks-3to4](https://huggingface.co/datasets/Jiayi-Pan/Countdown-Tasks-3to4) dataset, which contains samples with 3 to 4 numbers and solutions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8e38a8e-c826-420d-958c-9d433af55375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset from Hugging Face Hub\n",
    "dataset_id = \"Jiayi-Pan/Countdown-Tasks-3to4\"\n",
    "dataset = load_dataset(dataset_id, split=\"train\")\n",
    "# select a random subset of 50k samples\n",
    "dataset = dataset.shuffle(seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8de89e1c-0c34-495e-b862-8eec359c63c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and test\n",
    "train_test_split = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "test_dataset = train_test_split[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9701c15-6ab2-4f22-8421-f0f807f920f7",
   "metadata": {},
   "source": [
    "We are going to use the [FileSystem integration](https://huggingface.co/docs/datasets/filesystems) to upload our dataset to S3. We are using the `sagemaker_session.default_bucket()`, adjust this if you want to store the dataset in a different S3 bucket. We will use the S3 path later in our training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a981063-cfaa-46de-9be8-96f8413dd715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56a52350b914783b706b7e8096704ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/442 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09d43dd73cc4a3ab83c25c7d8c603f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data uploaded to:\n",
      "s3://sagemaker-us-east-1-783764584149/datasets/grpo-sm-test/train/dataset.json\n",
      "Test data uploaded to:\n",
      "s3://sagemaker-us-east-1-783764584149/datasets/grpo-sm-test/test/dataset.json\n",
      "https://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-east-1-783764584149/?region=us-east-1&prefix=datasets/grpo-sm-test/\n"
     ]
    }
   ],
   "source": [
    "# save train_dataset to s3 using our SageMaker session\n",
    "input_path = f's3://{sagemaker_session.default_bucket()}/datasets/grpo-sm-test'\n",
    "\n",
    "# Save datasets to s3\n",
    "# We will fine tune only with 20 records due to limited compute resource for the workshop\n",
    "train_dataset.to_json(f\"{input_path}/train/dataset.json\", orient=\"records\")\n",
    "train_dataset_s3_path = f\"{input_path}/train/dataset.json\"\n",
    "test_dataset.to_json(f\"{input_path}/test/dataset.json\", orient=\"records\")\n",
    "test_dataset_s3_path = f\"{input_path}/test/dataset.json\"\n",
    "print(f\"Training data uploaded to:\")\n",
    "print(train_dataset_s3_path)\n",
    "print(f\"Test data uploaded to:\")\n",
    "print(test_dataset_s3_path)\n",
    "print(f\"https://s3.console.aws.amazon.com/s3/buckets/{sagemaker_session.default_bucket()}/?region={sagemaker_session.boto_region_name}&prefix={input_path.split('/', 3)[-1]}/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb6afc-915d-480a-8b1c-cf5254f40a69",
   "metadata": {},
   "source": [
    "## 3. GRPO on Amazon SageMaker using python sdk\n",
    "\n",
    "We are now ready to fine-tune our model. We will use the [GRPOTrainer](https://huggingface.co/docs/trl/main/en/grpo_trainer) from `trl` to train our model. The `GRPOTrainer` is a subclass of the `Trainer` from the `transformers`. We prepared a script [train.py](../scripts/train.py) which will loads the dataset from disk, prepare the model, tokenizer and start the training. It usees the [GRPOTrainer](https://huggingface.co/docs/trl/main/en/grpo_trainer) from `trl` to ftrain our model. \n",
    "\n",
    "For configuration we use `TrlParser`, that allows us to provide hyperparameters in a yaml file. This `yaml` will be uploaded and provided to Amazon SageMaker similar to our datasets. Below is the config file for GRPO on ml.p4d.24xlarge 40GB GPUs. We are saving the config file as `args.yaml` and upload it to S3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "965bc2e3-5ba6-49e6-bd79-232e7e35a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat > ./args.yaml <<EOF\n",
    "hf_token: \"\" # Use HF token to login into Hugging Face to access the DeepSeek distilled models\n",
    "wandb_token: \"\"\n",
    "model_id: \"Qwen/Qwen2.5-0.5B-Instruct\"      # Hugging Face model id, replace it with 70b if needeed\n",
    "max_seq_length: 1024  #512 # 2048               # max sequence length for model and packing of the dataset\n",
    "# sagemaker specific parameters\n",
    "train_dataset_path: \"/opt/ml/input/data/train/\" # path to where SageMaker saves train dataset\n",
    "test_dataset_path: \"/opt/ml/input/data/test/\"   # path to where SageMaker saves test dataset\n",
    "\n",
    "output_dir: \"/opt/ml/model/Qwen-GRPO/output\"              # path to where SageMaker will upload the model \n",
    "# training parameters\n",
    "report_to: \"wandb\"             # report metrics to wandb\n",
    "learning_rate: 0.0003                  # learning rate 2e-4\n",
    "lr_scheduler_type: \"constant\"          # learning rate scheduler\n",
    "num_train_epochs: 1                  # number of training epochs\n",
    "per_device_train_batch_size: 10       # batch size per device during training\n",
    "per_device_eval_batch_size: 8         # batch size for evaluation\n",
    "gradient_accumulation_steps: 2        # number of steps before performing a backward/update pass\n",
    "optim: adamw_torch                     # use torch adamw optimizer\n",
    "logging_steps: 10                      # log every 10 steps\n",
    "save_strategy: epoch                   # save checkpoint every epoch\n",
    "evaluation_strategy: epoch             # evaluate every epoch\n",
    "max_grad_norm: 0.3                     # max gradient norm\n",
    "warmup_ratio: 0.03                     # warmup ratio\n",
    "bf16: true                             # use bfloat16 precision\n",
    "tf32: true                             # use tf32 precision\n",
    "gradient_checkpointing: true           # use gradient checkpointing to save memory\n",
    "\n",
    "weight_decay: 0.01\n",
    "warmup_steps: 100\n",
    "# offload FSDP parameters: https://huggingface.co/docs/transformers/main/en/fsdp\n",
    "fsdp: \"full_shard auto_wrap\" # remove offload if enough GPU memory\n",
    "fsdp_config:\n",
    "  backward_prefetch: \"backward_pre\"\n",
    "  forward_prefetch: \"false\"\n",
    "  use_orig_params: \"false\"\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "258af730-31ec-4452-9fb0-bbb2aebb6d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training config uploaded to:\n",
      "s3://sagemaker-us-east-1-783764584149/datasets/grpo-sm-test/config/args.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "# upload the model yaml file to s3\n",
    "model_yaml = \"args.yaml\"\n",
    "train_config_s3_path = S3Uploader.upload(local_path=model_yaml, desired_s3_uri=f\"{input_path}/config\")\n",
    "\n",
    "print(f\"Training config uploaded to:\")\n",
    "print(train_config_s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d29affd-61e1-4452-8908-5dc1a07a53e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.6.0-gpu-py312-cu126-ubuntu22.04-sagemaker'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image_uri = (\n",
    "#     f\"658645717510.dkr.ecr.{sagemaker_session.boto_session.region_name}.amazonaws.com/smdistributed-modelparallel:2.4.1-gpu-py311-cu121\"\n",
    "# )\n",
    "image_uri = (\n",
    "    f'763104351884.dkr.ecr.{sagemaker_session.boto_session.region_name}.amazonaws.com/pytorch-training:2.6.0-gpu-py312-cu126-ubuntu22.04-sagemaker'\n",
    ")\n",
    "\n",
    "image_uri\n",
    "\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f1b5917-8221-4228-8158-bc64fecd5e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SageMaker PyTorch Estimator\n",
    "\n",
    "# define Training Job Name \n",
    "job_name = f'Qwen-GRPO'\n",
    "\n",
    "pytorch_estimator = PyTorch(\n",
    "    entry_point= 'train.py',\n",
    "    source_dir=\"./scripts\",\n",
    "    job_name=job_name,\n",
    "    base_job_name=job_name,\n",
    "    max_run=10800,\n",
    "    role=role,\n",
    "    #framework_version=\"2.2.0\",\n",
    "    image_uri = image_uri,\n",
    "    py_version=\"py310\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p4d.24xlarge\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    disable_output_compression=True,\n",
    "    keep_alive_period_in_seconds=1800,\n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}},\n",
    "    hyperparameters={\n",
    "        \"config\": \"/opt/ml/input/data/config/args.yaml\" # path to TRL config which was uploaded to s3\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7aace45a-909d-44a1-a6cf-0e7b2ed51e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 's3://sagemaker-us-east-1-783764584149/datasets/grpo-sm-test/train/dataset.json',\n",
       " 'test': 's3://sagemaker-us-east-1-783764584149/datasets/grpo-sm-test/test/dataset.json',\n",
       " 'config': 's3://sagemaker-us-east-1-783764584149/datasets/grpo-sm-test/config/args.yaml'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a data input dictonary with our uploaded s3 uris\n",
    "data = {\n",
    "  'train': train_dataset_s3_path,\n",
    "  'test': test_dataset_s3_path,\n",
    "  'config': train_config_s3_path\n",
    "  }\n",
    "\n",
    "# Check input channels configured \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5436b7a7-4c13-4d6c-8477-aa4f1d91c068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/28/25 17:36:39] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/telemetry/telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/telemetry/telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/28/25 17:36:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=978841;file:///opt/conda/lib/python3.12/site-packages/sagemaker/telemetry/telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=604538;file:///opt/conda/lib/python3.12/site-packages/sagemaker/telemetry/telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name: Qwen-GRPO-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-28-17-36-39-247     <a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name: Qwen-GRPO-\u001b[1;36m2025\u001b[0m-04-28-17-36-39-247     \u001b]8;id=226017;file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=99729;file:///opt/conda/lib/python3.12/site-packages/sagemaker/session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-28 17:36:39 Starting - Starting the training job."
     ]
    }
   ],
   "source": [
    "# starting the train job with our uploaded datasets as input\n",
    "pytorch_estimator.fit(data, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547e6a91-9bb2-4814-8567-7982b37e9fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec319329-6634-4c4d-808e-afdba8e9cb40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8957409-9c3b-4e66-9d0e-ca500473e7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210b3397-9538-4ceb-93b0-597095f2c39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0894542-e534-42dd-a6a3-00531d7d61b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
