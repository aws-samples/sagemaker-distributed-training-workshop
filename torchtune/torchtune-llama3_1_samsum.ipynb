{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0af5654-1925-46a1-be8d-c4b57f59cf26",
   "metadata": {},
   "source": [
    "# Fine-tune Llama 3.1 models using torchtune on Amazon SageMaker\n",
    "\n",
    "In this notebook, we are using Metaâ€™s torchtune library to fine-tune Llama 3.1 8B model with LoRA fine-tuning strategies on Amazon SageMaker training. \n",
    "\n",
    "**torchtune** is a Native-PyTorch library that aims to democratize and streamline the fine-tuning process for LLMs, making it easier for researchers, developers, and organizations to adapt these powerful LLMs to their specific needs and constraints. \n",
    "\n",
    "In this use case, we are walking through an end-to-end example on how you can fine-tune a Llama 3.1 8B model with LoRA, run generation in memory, and optionally quantize and evaluate the model  using torchtune and SageMaker training.  \n",
    "\n",
    "Recipes, prompt templates, configs and datasets are completely configurable and allows you to align torchtune to your requirements. To demonstrate this, we will use a custom prompt template in this use case with the open source dataset Samsung/samsum from the Hugging Face hub.\n",
    "\n",
    "We are fine-tune using torchtune multi-device LoRA recipe (lora_finetune_distributed) and use the SageMaker customized version of Llama 3.1 8B  default config (llama3_1/8B_lora)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99414016-e912-4201-bf86-2c92b42dcdbb",
   "metadata": {},
   "source": [
    "## 1. Setup Development Environment\n",
    "\n",
    "Our first step is to install torchtune and SageMaker Libraries we need on the client to correctly prepare our dataset and start our training/evaluations jobs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17185d9-8554-4db4-8a48-37851ba243c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install \"sagemaker\" \"boto3\" \"datasets\" \"py7zr\" --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f8eb12-c7f6-4bfd-85af-da0cd654a258",
   "metadata": {},
   "source": [
    "If you are going to use Sagemaker in a local environment. You need access to an IAM Role with the required permissions for Sagemaker. You can find [here](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) more about it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d3628-51cc-4b17-adf0-537b84949621",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker, boto3, time, json\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from typing import Dict, Any\n",
    "from pprint import pprint\n",
    "from sagemaker.inputs import FileSystemInput\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client(\"iam\")\n",
    "    role = iam.get_role(RoleName=\"sagemaker_execution_role\")[\"Role\"][\"Arn\"]\n",
    "\n",
    "sagemaker_session_bucket = None\n",
    "if sagemaker_session_bucket is None and sagemaker_session is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sagemaker_session_bucket}\")\n",
    "print(f\"sagemaker session region: {sagemaker_session.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e49d5-94c5-4f33-91ca-09b57f9ee5ae",
   "metadata": {},
   "source": [
    "## Pre-Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c602c1df-bbea-45f3-b0ba-2042417c72d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Samsung/samsum\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b728a5a8-7784-4a83-b104-0bfdfa60e741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_sample=dataset['train'].select(range(100))\n",
    "\n",
    "dataset_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a6198e-d81a-4fda-ae39-48dc8c623099",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_sample.to_json('./dataset/samsum_train.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed1de8-0553-46e3-926e-72763d13c332",
   "metadata": {},
   "source": [
    "## Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9986c5ff-a5e6-40d3-8adb-7d1e2179eae2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#1. CF Stack Name\n",
    "stack_name='cf'\n",
    "\n",
    "#2. Region name\n",
    "region= sagemaker_session.boto_region_name\n",
    "\n",
    "#3. Model that we will fine-tune\n",
    "model_id=\"meta-llama/Meta-Llama-3.1-8B\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac1eaf-3f96-46c7-a75e-b55efeafeab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get EFS-id, private-subnet-id and EFS-id for next step of fine-tuning\n",
    "\n",
    "def get_stack_outputs(stack_name, region='us-west-2'):\n",
    "    \"\"\"\n",
    "    Retrieves all outputs from a CloudFormation stack.\n",
    "    \n",
    "    :param stack_name: Name of the CloudFormation stack\n",
    "    :param region: AWS region where the stack is deployed (default is 'us-east-1')\n",
    "    :return: Dictionary of stack outputs\n",
    "    \"\"\"\n",
    "    cfn_client = boto3.client('cloudformation', region_name=region)\n",
    "    \n",
    "    try:\n",
    "        response = cfn_client.describe_stacks(StackName=stack_name)\n",
    "        stack_outputs = response['Stacks'][0]['Outputs']\n",
    "        \n",
    "       # print(stack_outputs)\n",
    "        # Convert the list of outputs to a dictionary for easier access\n",
    "        outputs_dict = {output['OutputKey']: output['OutputValue'] for output in stack_outputs}\n",
    "       \n",
    "\n",
    "        return outputs_dict\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving stack outputs: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "outputs = get_stack_outputs(stack_name, region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7915696a-1555-40ae-9945-bb7c54db53a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b30ab5c",
   "metadata": {},
   "source": [
    "## Define S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0517efca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. S3 url with model weights\n",
    "s3_model_artifacts=outputs[\"S3ModelUri\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e151cc3-2d2b-4808-b55f-cf5828e6ff0f",
   "metadata": {},
   "source": [
    "## Define EFS and networking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c50f0f4-1a7c-4771-b8b5-ddf40003974e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define one-time network configuration for VPC to use EFS\n",
    "# This example has been optimized and tested on EFS. If you want to use S3, please change the config files to match S3 directory path\n",
    "\n",
    "\n",
    "use_efs=True\n",
    "\n",
    "# VPC config\n",
    "network_config={\n",
    "\n",
    "   \"subnets\": [outputs['SubnetID1'], outputs['SubnetID2'], outputs['SubnetID3'], outputs['SubnetID4'], outputs['SubnetID5'], outputs['SubnetID6']],\n",
    "   \"security_group_ids\": [outputs['SecurityGroup']] # e.g. [\"sg-xxxx\"]\n",
    "}\n",
    "\n",
    "# EFS file system id \n",
    "efs_file_system_id=outputs['EFSFileSystemId'] # e.g. 'fs-xxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3951aa5-d0cb-4d4b-b5b4-7384c6efcdbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_config, efs_file_system_id\n",
    "\n",
    "## add all 6 subnets to network_config[\"subnets\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c537ffb-0e27-4548-9eb4-6c9aaf30c962",
   "metadata": {},
   "source": [
    "## Define PyTorch Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522fdeff-eb4d-4be3-a93b-d5999497d079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_downloaded_model = \"test\"\n",
    "\n",
    "def create_pytorch_estimator(**kwargs: Any) -> PyTorch:\n",
    "    \"\"\"\n",
    "    Create a PyTorch estimator for SageMaker training with dynamic configuration.\n",
    "\n",
    "    Args:\n",
    "    **kwargs: Arbitrary keyword arguments for PyTorch estimator configuration.\n",
    "\n",
    "    Returns:\n",
    "    PyTorch: Configured PyTorch estimator.\n",
    "\n",
    "    Raises:\n",
    "    KeyError: If required parameters are missing in kwargs.\n",
    "    \"\"\"        \n",
    "    \n",
    "    job_name = f'torchtune-{kwargs[\"hyperparameters\"][\"tune_action\"]}'\n",
    "    \n",
    "    # Upload configs to S3 folder\n",
    "    inputs = sagemaker_session.upload_data(path=\"config\", bucket=sagemaker_session_bucket, key_prefix=\"config\")\n",
    "    templates = sagemaker_session.upload_data(path=\"custom_template\", bucket=sagemaker_session_bucket, key_prefix=\"templates\")\n",
    "    dataset = sagemaker_session.upload_data(path=\"dataset\", bucket=sagemaker_session_bucket, key_prefix=\"dataset\")\n",
    "\n",
    "    print(\"torchtune configs uploaded to:{} \\n\".format(inputs))\n",
    "    print(\"and to:{} \\n\".format(templates))\n",
    "\n",
    "    env_var = {\n",
    "        \"SAGEMAKER_REQUIREMENTS\": \"requirements.txt\",\n",
    "    }\n",
    "\n",
    "    # Default configuration\n",
    "    estimator_config = {\n",
    "        \"entry_point\": \"launcher.py\",\n",
    "        \"source_dir\": \"./scripts\",\n",
    "        \"base_job_name\": job_name,\n",
    "        \"max_run\": 86400,\n",
    "        \"framework_version\": \"2.4.0\",\n",
    "        \"py_version\": \"py311\",\n",
    "        \"disable_output_compression\": True,\n",
    "        \"keep_alive_period_in_seconds\": 1800,\n",
    "        \"env\": env_var,\n",
    "        \"role\": role,\n",
    "        \"sagemaker_session\": sagemaker_session,\n",
    "        \"disable_profiler\":True,\n",
    "        \"debugger_hook_config\":False\n",
    "    }\n",
    "\n",
    "    # Update with provided kwargs\n",
    "    estimator_config.update(kwargs)\n",
    "\n",
    "    # Ensure required parameters are present\n",
    "    required_params = ['instance_type', 'instance_count', 'hyperparameters']\n",
    "    for param in required_params:\n",
    "        if param not in estimator_config:\n",
    "            raise KeyError(f\"Missing required parameter: {param}\")\n",
    "\n",
    "    # Configure EFS if specified\n",
    "    if use_efs:\n",
    "        required_keys = {'subnets', 'security_group_ids'}\n",
    "        missing_keys = set(required_keys) - set(network_config.keys())\n",
    "        \n",
    "        if missing_keys:\n",
    "            raise ValueError(f\"Missing required keys: {', '.join(missing_keys)}\")\n",
    "    \n",
    "        for key, value in network_config.items():\n",
    "            if value is None or len(value) == 0:\n",
    "                raise ValueError(f\"Missing required value for {key}: {value}\")\n",
    "                \n",
    "        estimator_config.update(network_config)\n",
    "        \n",
    "    # Remove 'use_efs' from config as it's not a PyTorch estimator parameter\n",
    "    estimator_config[\"hyperparameters\"].pop('use_efs', None)\n",
    "    \n",
    "    global use_downloaded_model\n",
    "    use_downloaded_model = estimator_config[\"hyperparameters\"][\"use_downloaded_model\"]\n",
    "    use_downloaded_model=bool(use_downloaded_model) and use_downloaded_model.lower() not in ('false', '0', 'no', 'n', 'off')\n",
    "        \n",
    "    print(\"SageMaker PyTorch Estimator: \\n\")\n",
    "    pprint(estimator_config)\n",
    "\n",
    "    return PyTorch(**estimator_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c509b-eb52-4d2a-a2be-23fa35a2d984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def execute_task(estimator):\n",
    "    \"\"\"\n",
    "    Execute the task using the provided estimator and input data channels.\n",
    "\n",
    "    Args:\n",
    "    estimator (sagemaker.estimator.Estimator): The SageMaker estimator to use for training.\n",
    "    s3_config_bucket (str): The S3 bucket path for the configuration data.\n",
    "    \"\"\"\n",
    "        \n",
    "    if use_efs:\n",
    "        if efs_file_system_id is None or len(efs_file_system_id) == 0:\n",
    "            raise ValueError(f\"Missing required value for efs_file_system_id: {efs_file_system_id}\")\n",
    "        \n",
    "        # Define the EFS input\n",
    "        efs_input = FileSystemInput(\n",
    "            file_system_id=efs_file_system_id,\n",
    "            file_system_type='EFS',\n",
    "            directory_path='/',\n",
    "            file_system_access_mode='rw'\n",
    "        )\n",
    "    else:\n",
    "        s3 = boto3.client('s3')\n",
    "        s3.put_object(Bucket=sagemaker_session_bucket, Key=\"artifacts\")\n",
    "    \n",
    "    s3_config_bucket = f\"s3://{sagemaker_session_bucket}/config\"\n",
    "    s3_custom_template = f\"s3://{sagemaker_session_bucket}/templates\"\n",
    "    s3_model_store = f\"s3://{sagemaker_session_bucket}/artifacts\"\n",
    "    s3_dataset = f\"s3://{sagemaker_session_bucket}/dataset\"\n",
    "\n",
    "    # Define the data channels\n",
    "    data_channels = {\n",
    "        \"config\": s3_config_bucket,\n",
    "        \"model\": efs_input if use_efs else s3_model_store,\n",
    "        \"templates\":s3_custom_template,\n",
    "        \"dataset\":s3_dataset,\n",
    "        \"model_artifacts\": s3_model_artifacts\n",
    "    }\n",
    "    \n",
    "    if use_downloaded_model:\n",
    "        data_channels.pop('model_artifacts', None)\n",
    "\n",
    "    print(f'data_channels:{data_channels}')\n",
    "    \n",
    "    # Fit the estimator with the input data channels\n",
    "    estimator.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b6bcec-c599-4dba-b7e7-1640b59575a9",
   "metadata": {},
   "source": [
    "## Define SageMaker Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff8c12e-c882-46fb-9bc0-0b621f75c5a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set common parameters\n",
    "hyperparam_common_values={}\n",
    "\n",
    "hyperparam_common_values[\"model_id\"]=model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bc94db-ab9e-4e93-9c02-ce120c6df7a7",
   "metadata": {},
   "source": [
    "## Define SageMaker Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafb78b9-3b33-45b6-b1b4-1a538dabca6a",
   "metadata": {},
   "source": [
    "Define SageMaker tasks for every specific model customization lifecycle step. Each task defines the configuration of the compute cluster that SageMaker will sping up to run the specific torchtune recipe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3241c0-5898-4013-a7a1-a27de70e250b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt=r'{\"dialogue\":\"Amanda: I baked  cookies. Do you want some?\\r\\nJerry: Sure \\r\\nAmanda: I will bring you tomorrow :-)\"}'\n",
    "\n",
    "sagemaker_tasks={}\n",
    "\n",
    "# Define SageMaker task that will create a specifc SageMaker PyTorch estimator for a torchtune recipe\n",
    "# Make sure keys are defined in the same format \n",
    "sagemaker_tasks={\n",
    "    \"fine-tune\":{\n",
    "        \"hyperparameters\":{\n",
    "            \"tune_config_name\":\"config_l3.1_8b_qlora.yaml\",\n",
    "            \"tune_action\":\"fine-tune\",\n",
    "            \"use_downloaded_model\":\"false\",\n",
    "            \"tune_recipe\":\"lora_finetune_distributed\" # check torchtune documentation or run \"tune ls\" to find all recipes available\n",
    "            },\n",
    "        \"instance_count\":1,\n",
    "        \"instance_type\":\"ml.g5.2xlarge\",  \n",
    "    },\n",
    "    \"generate_inference_on_trained\":{\n",
    "        \"hyperparameters\":{\n",
    "            \"tune_config_name\":\"config_l3.1_8b_gen_trained.yaml\",\n",
    "            \"tune_action\":\"generate-trained\",\n",
    "            \"use_downloaded_model\":\"true\",\n",
    "            #\"prompt\":json.dumps(prompt)\n",
    "            },\n",
    "        \"instance_count\":1,\n",
    "        \"instance_type\":\"ml.g5.2xlarge\",\n",
    "    },\n",
    "    \"generate_inference_on_original\":{\n",
    "        \"hyperparameters\":{\n",
    "            \"tune_config_name\":\"config_l3.1_8b_gen_orig.yaml\",\n",
    "            \"tune_action\":\"generate-original\",\n",
    "            \"use_downloaded_model\":\"true\",\n",
    "            #\"prompt\":json.dumps(prompt)\n",
    "            },\n",
    "        \"instance_count\":1,\n",
    "        \"instance_type\":\"ml.g5.2xlarge\",\n",
    "    },\n",
    "    \"evaluate_trained_model\":{\n",
    "        \"hyperparameters\":{\n",
    "            \"tune_config_name\":\"config_l3.1_8b_eval_trained.yaml\",\n",
    "            \"tune_action\":\"run-eval\",\n",
    "            \"use_downloaded_model\":\"true\",\n",
    "            \"prompt\":json.dumps(prompt)\n",
    "            },\n",
    "        \"instance_count\":1,\n",
    "        \"instance_type\":\"ml.g5.2xlarge\",\n",
    "    }\n",
    "}\n",
    "\n",
    "for k,v in sagemaker_tasks.items():\n",
    "    sagemaker_tasks[k][\"hyperparameters\"].update(hyperparam_common_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba94a782-ccc7-4bc7-99f4-f9118c19bcf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e0be6-82f9-46d9-9777-7008a3c2d140",
   "metadata": {},
   "source": [
    "## Fine Tune Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50333917-2f58-4cb2-9051-79e7fd87ed67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"  *** TASK for the Job. Select one of the below tasks: ***\n",
    "  {fine-tune, generate_inference_on_trained,generate_inference_on_original,quantize_trained_model, \n",
    "   generate_inference_on_trained_quant,evaluate_trained_model} \"\"\"\n",
    "    \n",
    "Task=\"fine-tune\"\n",
    "\n",
    "# Optionally print or override the task dictionary\n",
    "#pprint(sagemaker_tasks[Task])\n",
    "\n",
    "estimator=create_pytorch_estimator(**sagemaker_tasks[Task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d86dada-7684-461e-9354-57c43736c940",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "execute_task(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994fd603-eb2c-451e-bed5-611636f310aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate Trained Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc62485-2663-4342-b72e-d9bafa499330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"  *** TASK for the Job. Select one of the above below tasks: ***\n",
    "  {fine-tune, generate_inference_on_trained,generate_inference_on_original,quantize_trained_model, \n",
    "   generate_inference_on_trained_quant,evaluate_trained_model} \"\"\"\n",
    "\n",
    "Task=\"generate_inference_on_trained\" \n",
    "\n",
    "# You can overwrite any parameters in the SageMaker task as you see fit for your experimentation\n",
    "prompt=r'{\"dialogue\":\"Amanda: I baked  cookies. Do you want some?\\r\\nJerry: Sure \\r\\nAmanda: I will bring you tomorrow :-)\"}'\n",
    "\n",
    "sagemaker_tasks[Task]['hyperparameters']['prompt']=json.dumps(prompt)\n",
    "\n",
    "estimator=create_pytorch_estimator(**sagemaker_tasks[Task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03642d0f-d3ee-4d4e-ac75-a2a815654fca",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "execute_task(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e477130-2407-4a71-a39b-9e9ee029308f",
   "metadata": {},
   "source": [
    "## Generate Original Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6185b7-1427-400a-a717-8d1199796b78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"  *** TASK for the Job. Select one of the above below tasks: ***\n",
    "  {fine-tune, generate_inference_on_trained,generate_inference_on_original,quantize_trained_model, \n",
    "   generate_inference_on_trained_quant,evaluate_trained_model} \"\"\"\n",
    "\n",
    "Task=\"generate_inference_on_original\" \n",
    "\n",
    "# You can overwrite any parameters in the SageMaker task as you see fit for your experimentation\n",
    "prompt=r'{\"dialogue\":\"Amanda: I baked  cookies. Do you want some?\\r\\nJerry: Sure \\r\\nAmanda: I will bring you tomorrow :-)\"}'\n",
    "\n",
    "sagemaker_tasks[Task]['hyperparameters']['prompt']=json.dumps(prompt)\n",
    "\n",
    "#pprint(sagemaker_tasks[Task])\n",
    "\n",
    "estimator=create_pytorch_estimator(**sagemaker_tasks[Task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d80b3-53c2-4de7-a452-4c7013cdd7ff",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "execute_task(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8947846-606d-445f-b0b4-8b61a51162f6",
   "metadata": {},
   "source": [
    "## Evaluate Trained Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e900af-4569-4aa5-b69e-df01eec3b74f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"  *** TASK for the Job. Select one of the above below tasks: ***\n",
    "  {fine-tune, generate_inference_on_trained,generate_inference_on_original,quantize_trained_model, \n",
    "   generate_inference_on_trained_quant,evaluate_trained_model} \"\"\"\n",
    "\n",
    "Task=\"evaluate_trained_model\" \n",
    "\n",
    "sagemaker_tasks[Task]['hyperparameters']['tune_config_name']='config_l3.1_8b_eval_trained.yaml'\n",
    "\n",
    "estimator=create_pytorch_estimator(**sagemaker_tasks[Task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d10eff-be2b-4627-b4c0-33f8132a83a9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "execute_task(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1516ad-aa22-4217-84c7-76d5ea3da795",
   "metadata": {},
   "source": [
    "## Evaluate Original Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7005e839-a2ce-499c-966c-9dcd658a96a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"  *** TASK for the Job. Select one of the above below tasks: ***\n",
    "  {fine-tune, generate_inference_on_trained,generate_inference_on_original,quantize_trained_model, \n",
    "   generate_inference_on_trained_quant,evaluate_trained_model} \"\"\"\n",
    "\n",
    "Task=\"evaluate_trained_model\" \n",
    "\n",
    "sagemaker_tasks[Task]['hyperparameters']['tune_config_name']='config_l3.1_8b_eval_original.yaml'\n",
    "\n",
    "estimator=create_pytorch_estimator(**sagemaker_tasks[Task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b70ff9-ced0-4541-bcad-78b23ef96ca3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execute_task(estimator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
